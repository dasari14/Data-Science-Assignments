{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "56f3f42a-b92e-4112-b5e2-2821c368c33e",
      "metadata": {
        "id": "56f3f42a-b92e-4112-b5e2-2821c368c33e"
      },
      "source": [
        "1. Data Exploration and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "97db0a89-3f2a-45a4-b80b-440fb37de819",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97db0a89-3f2a-45a4-b80b-440fb37de819",
        "outputId": "1d4fd707-d5c8-43f0-dcd2-12b1593ff237"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary Statistics:\n",
            "                 age        fnlwgt  education_num  capital_gain  capital_loss  \\\n",
            "count  32561.000000  3.256100e+04   32561.000000  32561.000000  32561.000000   \n",
            "mean      38.581647  1.897784e+05      10.080679   1077.648844     87.303830   \n",
            "std       13.640433  1.055500e+05       2.572720   7385.292085    402.960219   \n",
            "min       17.000000  1.228500e+04       1.000000      0.000000      0.000000   \n",
            "25%       28.000000  1.178270e+05       9.000000      0.000000      0.000000   \n",
            "50%       37.000000  1.783560e+05      10.000000      0.000000      0.000000   \n",
            "75%       48.000000  2.370510e+05      12.000000      0.000000      0.000000   \n",
            "max       90.000000  1.484705e+06      16.000000  99999.000000   4356.000000   \n",
            "\n",
            "       hours_per_week  \n",
            "count    32561.000000  \n",
            "mean        40.437456  \n",
            "std         12.347429  \n",
            "min          1.000000  \n",
            "25%         40.000000  \n",
            "50%         40.000000  \n",
            "75%         45.000000  \n",
            "max         99.000000   \n",
            "\n",
            "Check for missing values:\n",
            " age               0\n",
            "workclass         0\n",
            "fnlwgt            0\n",
            "education         0\n",
            "education_num     0\n",
            "marital_status    0\n",
            "occupation        0\n",
            "relationship      0\n",
            "race              0\n",
            "sex               0\n",
            "capital_gain      0\n",
            "capital_loss      0\n",
            "hours_per_week    0\n",
            "native_country    0\n",
            "income            0\n",
            "dtype: int64 \n",
            "\n",
            "Data Types:\n",
            " age                int64\n",
            "workclass         object\n",
            "fnlwgt             int64\n",
            "education         object\n",
            "education_num      int64\n",
            "marital_status    object\n",
            "occupation        object\n",
            "relationship      object\n",
            "race              object\n",
            "sex               object\n",
            "capital_gain       int64\n",
            "capital_loss       int64\n",
            "hours_per_week     int64\n",
            "native_country    object\n",
            "income            object\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "#Load the dataset and conduct basic data exploration:\n",
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(r\"/content/adult_with_headers.csv\")\n",
        "\n",
        "#Display summary statistics\n",
        "\n",
        "print(\"Summary Statistics:\\n\", data.describe(), \"\\n\")\n",
        "\n",
        "#Check for missing values\n",
        "print(\"Check for missing values:\\n\", data.isnull().sum(), \"\\n\")\n",
        "\n",
        "#Display data types\n",
        "print(\"Data Types:\\n\", data.dtypes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "fbec6524-3a7a-4d3a-ac93-5c57f5669ecb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbec6524-3a7a-4d3a-ac93-5c57f5669ecb",
        "outputId": "7c7e0629-74a8-470b-ea5f-b068f27f7882"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ],
      "source": [
        "#Handle missing values\n",
        "print(data.isnull().any().any())\n",
        "#The output is False, which means that there are no missing values in this dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "b5a34831-131a-4d61-956c-a4f7fe6fb5d2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5a34831-131a-4d61-956c-a4f7fe6fb5d2",
        "outputId": "3d4a6c52-96ca-4e2e-a94c-bcde1caf2a68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standard scaling\n",
            "        age    fnlwgt  education_num  capital_gain  capital_loss  \\\n",
            "0  0.030671 -1.063611       1.134739      0.148453      -0.21666   \n",
            "1  0.837109 -1.008707       1.134739     -0.145920      -0.21666   \n",
            "2 -0.042642  0.245079      -0.420060     -0.145920      -0.21666   \n",
            "3  1.057047  0.425801      -1.197459     -0.145920      -0.21666   \n",
            "4 -0.775768  1.408176       1.134739     -0.145920      -0.21666   \n",
            "\n",
            "   hours_per_week  \n",
            "0       -0.035429  \n",
            "1       -2.222153  \n",
            "2       -0.035429  \n",
            "3       -0.035429  \n",
            "4       -0.035429  \n",
            "Min-Max scaling\n",
            "        age    fnlwgt  education_num  capital_gain  capital_loss  \\\n",
            "0  0.301370  0.044302       0.800000       0.02174           0.0   \n",
            "1  0.452055  0.048238       0.800000       0.00000           0.0   \n",
            "2  0.287671  0.138113       0.533333       0.00000           0.0   \n",
            "3  0.493151  0.151068       0.400000       0.00000           0.0   \n",
            "4  0.150685  0.221488       0.800000       0.00000           0.0   \n",
            "\n",
            "   hours_per_week  \n",
            "0        0.397959  \n",
            "1        0.122449  \n",
            "2        0.397959  \n",
            "3        0.397959  \n",
            "4        0.397959  \n"
          ]
        }
      ],
      "source": [
        "#Apply scaling techniques to numerical features\n",
        "\n",
        "#To apply standard scaling and min-max scaling to numerical features in the dataset, we use scikit-learn's StandardScaler and MinMaxScaler classes.\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "\n",
        "# Select numerical features for scaling\n",
        "numerical_features = ['age', 'fnlwgt', 'education_num', 'capital_gain', 'capital_loss', 'hours_per_week']\n",
        "\n",
        "# Standard Scaling\n",
        "scaler_standard = StandardScaler()\n",
        "data_standard_scaled = scaler_standard.fit_transform(data[numerical_features])\n",
        "data_standard_scaled = pd.DataFrame(data_standard_scaled, columns=numerical_features)  # Convert to DataFrame\n",
        "print(\"Standard scaling\")\n",
        "print(data_standard_scaled.head())\n",
        "\n",
        "# Min-Max Scaling\n",
        "scaler_minmax = MinMaxScaler()\n",
        "data_minmax_scaled = scaler_minmax.fit_transform(data[numerical_features])\n",
        "data_minmax_scaled = pd.DataFrame(data_minmax_scaled, columns=numerical_features)  # Convert to DataFrame\n",
        "print(\"Min-Max scaling\")\n",
        "print(data_minmax_scaled.head())\n"
      ]
    },
    {
      "cell_type": "raw",
      "id": "8b9f4f11-bbf4-4147-aaef-a8bf574f0484",
      "metadata": {
        "id": "8b9f4f11-bbf4-4147-aaef-a8bf574f0484"
      },
      "source": [
        "Scenarios where each scaling technique is preferred and why:\n",
        "\n",
        "1. Standard Scaling (Z-score normalization):\n",
        "\n",
        "Preferred Scenario: Standard scaling is often preferred when the features in the dataset have different units of measurement or different scales. It rescales the features so that they have the properties of a standard normal distribution with a mean of 0 and a standard deviation of 1. This scaling technique is particularly useful for algorithms that rely on the distribution of features, such as linear regression, logistic regression, support vector machines (SVM), and neural networks.\n",
        "\n",
        "2. Min-Max Scaling:\n",
        "\n",
        "Preferred Scenario: Min-Max scaling, also known as normalization, is preferred when we need to bound the features within a specific range, typically between 0 and 1. It's especially useful when we are working with algorithms that require features to be on a similar scale, such as K-nearest neighbors (KNN) and clustering algorithms like K-means."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5a61995-0a49-4724-ae9a-93653f14f3e8",
      "metadata": {
        "id": "a5a61995-0a49-4724-ae9a-93653f14f3e8"
      },
      "source": [
        "2. Encoding Techniques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b3758fc6-45b1-4c09-98bc-cea2ac70951d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3758fc6-45b1-4c09-98bc-cea2ac70951d",
        "outputId": "9309090e-45a7-4650-fdab-8fec3a815997"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       race_ Asian-Pac-Islander  race_ Black  race_ Other  race_ White  \\\n",
            "0                           0.0          0.0          0.0          1.0   \n",
            "1                           0.0          0.0          0.0          1.0   \n",
            "2                           0.0          0.0          0.0          1.0   \n",
            "3                           0.0          1.0          0.0          0.0   \n",
            "4                           0.0          1.0          0.0          0.0   \n",
            "...                         ...          ...          ...          ...   \n",
            "32556                       0.0          0.0          0.0          1.0   \n",
            "32557                       0.0          0.0          0.0          1.0   \n",
            "32558                       0.0          0.0          0.0          1.0   \n",
            "32559                       0.0          0.0          0.0          1.0   \n",
            "32560                       0.0          0.0          0.0          1.0   \n",
            "\n",
            "       sex_ Male  income_ >50K  \n",
            "0            1.0           0.0  \n",
            "1            1.0           0.0  \n",
            "2            1.0           0.0  \n",
            "3            1.0           0.0  \n",
            "4            0.0           0.0  \n",
            "...          ...           ...  \n",
            "32556        0.0           0.0  \n",
            "32557        1.0           1.0  \n",
            "32558        0.0           0.0  \n",
            "32559        1.0           0.0  \n",
            "32560        0.0           1.0  \n",
            "\n",
            "[32561 rows x 6 columns]\n",
            "       age  workclass  fnlwgt  education  education_num  marital_status  \\\n",
            "0       39          7   77516          9             13               4   \n",
            "1       50          6   83311          9             13               2   \n",
            "2       38          4  215646         11              9               0   \n",
            "3       53          4  234721          1              7               2   \n",
            "4       28          4  338409          9             13               2   \n",
            "...    ...        ...     ...        ...            ...             ...   \n",
            "32556   27          4  257302          7             12               2   \n",
            "32557   40          4  154374         11              9               2   \n",
            "32558   58          4  151910         11              9               6   \n",
            "32559   22          4  201490         11              9               4   \n",
            "32560   52          5  287927         11              9               2   \n",
            "\n",
            "       occupation  relationship    race      sex  capital_gain  capital_loss  \\\n",
            "0               1             1   White     Male          2174             0   \n",
            "1               4             0   White     Male             0             0   \n",
            "2               6             1   White     Male             0             0   \n",
            "3               6             0   Black     Male             0             0   \n",
            "4              10             5   Black   Female             0             0   \n",
            "...           ...           ...     ...      ...           ...           ...   \n",
            "32556          13             5   White   Female             0             0   \n",
            "32557           7             0   White     Male             0             0   \n",
            "32558           1             4   White   Female             0             0   \n",
            "32559           1             3   White     Male             0             0   \n",
            "32560           4             5   White   Female         15024             0   \n",
            "\n",
            "       hours_per_week  native_country  income  \n",
            "0                  40              39   <=50K  \n",
            "1                  13              39   <=50K  \n",
            "2                  40              39   <=50K  \n",
            "3                  40              39   <=50K  \n",
            "4                  40               5   <=50K  \n",
            "...               ...             ...     ...  \n",
            "32556              38              39   <=50K  \n",
            "32557              40              39    >50K  \n",
            "32558              40              39   <=50K  \n",
            "32559              20              39   <=50K  \n",
            "32560              40              39    >50K  \n",
            "\n",
            "[32561 rows x 15 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "#To apply One-Hot Encoding and Label Encoding to categorical variables based on the number of categories, we use scikit-learn's OneHotEncoder and LabelEncoder classes.\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "\n",
        "# Identify categorical variables\n",
        "categorical_variables = []\n",
        "for column in data.columns:\n",
        "    if data[column].dtype == 'object' and len(data[column].unique()) <= 5:\n",
        "        categorical_variables.append(column)\n",
        "\n",
        "# Apply One-Hot Encoding to categorical variables with less than 5 categories\n",
        "onehot_encoder = OneHotEncoder(sparse=False, drop='first')\n",
        "onehot_encoded = onehot_encoder.fit_transform(data[categorical_variables])\n",
        "onehot_encoded_df = pd.DataFrame(onehot_encoded, columns=[f\"{column}_{category}\"\n",
        "                                                         for column, categories in zip(categorical_variables, onehot_encoder.categories_)\n",
        "                                                         for category in categories[1:]])\n",
        "print(onehot_encoded_df)\n",
        "\n",
        "# Use Label Encoding for categorical variables with more than 5 categories\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoded_df = data.copy()\n",
        "for column in data.columns:\n",
        "    if data[column].dtype == 'object' and len(data[column].unique()) > 5:\n",
        "        label_encoded_df[column] = label_encoder.fit_transform(data[column])\n",
        "print(label_encoded_df)"
      ]
    },
    {
      "cell_type": "raw",
      "id": "650a4b52-615f-4a38-9e8e-fa2239eeb813",
      "metadata": {
        "id": "650a4b52-615f-4a38-9e8e-fa2239eeb813"
      },
      "source": [
        "Pros and Cons of One Hot Encoding and Label encoding\n",
        "\n",
        "One-Hot Encoding:\n",
        "\n",
        "Pros:\n",
        "\n",
        "- Maintains the ordinal relationship between categories.\n",
        "- Suitable for algorithms that assume no ordinal relationship between categories (e.g., decision trees, random forests).\n",
        "- Helps prevent the model from assigning incorrect ordinal values to categories.\n",
        "\n",
        "Cons:\n",
        "\n",
        "- Can lead to a high-dimensional and sparse feature space, especially for categorical variables with many unique categories.\n",
        "- Increases the complexity of the dataset, potentially leading to overfitting, especially with a large number of categories.\n",
        "- May not be suitable for algorithms sensitive to multicollinearity.\n",
        "\n",
        "Label Encoding:\n",
        "\n",
        "Pros:\n",
        "\n",
        "- Produces compact representations of categorical variables.\n",
        "- Preserves the ordinal relationship between categories, which can be beneficial for some algorithms (e.g., linear models, decision trees).\n",
        "- Reduces the dimensionality of the dataset, potentially reducing computational complexity.\n",
        "\n",
        "Cons:\n",
        "\n",
        "- Imposes an ordinal relationship on categorical variables, which may not be appropriate for algorithms that assume no ordinality.\n",
        "- Can lead to incorrect interpretations if the ordinality is not meaningful.\n",
        "- May not handle unseen categories during model deployment unless handled appropriately (e.g., with unknown category handling)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd798e93-f725-4a82-a508-d12a7be53f0c",
      "metadata": {
        "id": "dd798e93-f725-4a82-a508-d12a7be53f0c"
      },
      "source": [
        "3. Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "ba69c56b-9022-48f3-b5ee-f4cb1c0f8878",
      "metadata": {
        "id": "ba69c56b-9022-48f3-b5ee-f4cb1c0f8878"
      },
      "outputs": [],
      "source": [
        "#Features beneficial for the model\n",
        "\n",
        "#Feature 1: Capital Change\n",
        "data['capital_change'] = data['capital_gain'] - data['capital_loss']\n",
        "#This feature calculates the net capital change by subtracting capital_loss from capital_gain.\n",
        "#Rationale: While capital_gain and capital_loss are important individual features, combining them into a single feature can provide additional information about the overall\n",
        "#financial status of an individual. A positive value indicates a net capital gain, while a negative value indicates a net capital loss.\n",
        "\n",
        "#Feature 2: Education Years\n",
        "data['education_years'] = data['education_num'] + data['age']\n",
        "#This feature calculates the total number of years spent on education by summing up education_num and age.\n",
        "#Rationale: Education level and age are both important factors that can influence income.\n",
        "#By combining them into a single feature, we can capture the cumulative effect of education and age on income,\n",
        "#which might provide better predictive power to the model.\n",
        "\n",
        "#Log transformation to atleast one skewed numerical feature\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Apply log transformation to 'capital_gain'\n",
        "data['capital_gain_log'] = np.log1p(data['capital_gain'])\n",
        "#Justification: The 'capital_gain' feature is likely to be positively skewed, with a few individuals having very high capital gains compared to the majority.\n",
        "#This skewness can make the distribution non-normal, which can negatively impact the performance of certain machine learning algorithms\n",
        "#that assume normality or require symmetric distributions.By applying a log transformation, we can compress the range of values for 'capital_gain' while maintaining the relative differences between lower values. This helps in making the distribution more symmetric, reducing the impact of extreme values, and making the data more suitable for algorithms that assume normality or linear relationships between variables.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6c94f69-5a56-433f-b644-9466bd2bf5de",
      "metadata": {
        "id": "b6c94f69-5a56-433f-b644-9466bd2bf5de"
      },
      "source": [
        "4. Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "0c9d78f9-df32-4d12-ac23-d4631cb0e568",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c9d78f9-df32-4d12-ac23-d4631cb0e568",
        "outputId": "6910ebdb-b3c1-44ae-c30b-666ac790fad0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Encode categorical variables\n",
        "categorical_columns = data.select_dtypes(include=['object']).columns\n",
        "data_encoded = pd.get_dummies(data, columns=categorical_columns)\n",
        "\n",
        "# Remove missing values (if any)\n",
        "data_encoded.dropna(inplace=True)\n",
        "\n",
        "# Instantiate the Isolation Forest model\n",
        "isolation_forest = IsolationForest(contamination=0.05)  # Adjust contamination parameter as needed\n",
        "\n",
        "# Fit the model to the data and predict outliers\n",
        "outlier_labels = isolation_forest.fit_predict(data_encoded)\n",
        "\n",
        "# Remove outliers from the dataset\n",
        "data_no_outliers = data_encoded[outlier_labels == 1]\n"
      ]
    },
    {
      "cell_type": "raw",
      "id": "2b286489-4d1b-4417-8145-660dc1920902",
      "metadata": {
        "id": "2b286489-4d1b-4417-8145-660dc1920902"
      },
      "source": [
        "Impact of Outliers on Model Performance:\n",
        "\n",
        "Bias in Model Estimates: Outliers can significantly impact the estimates of statistical parameters such as mean and variance, leading to biased model predictions.\n",
        "Inflated Error Rates: Outliers can lead to inflated error rates, especially in models sensitive to outliers, such as linear regression.\n",
        "Distorted Relationships: Outliers can distort relationships between variables, leading to inaccurate interpretations of model coefficients and relationships.\n",
        "Decreased Model Robustness: Outliers can decrease the robustness of the model, making it less generalizable to new data.\n",
        "Removing outliers before modeling can help mitigate these issues and improve the overall performance and interpretability of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "1c82fb1c-4fa7-447c-9a5b-5470bbf417fb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c82fb1c-4fa7-447c-9a5b-5470bbf417fb",
        "outputId": "f11c7dc6-ac02-407e-a1a6-fb134590f6b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ppscore in /usr/local/lib/python3.10/dist-packages (1.3.0)\n",
            "Requirement already satisfied: pandas<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ppscore) (1.5.3)\n",
            "Requirement already satisfied: scikit-learn<2.0.0,>=0.20.2 in /usr/local/lib/python3.10/dist-packages (from ppscore) (1.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0.0,>=1.0.0->ppscore) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0.0,>=1.0.0->ppscore) (2023.4)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0.0,>=1.0.0->ppscore) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0.0,>=0.20.2->ppscore) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0.0,>=0.20.2->ppscore) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0.0,>=0.20.2->ppscore) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas<2.0.0,>=1.0.0->ppscore) (1.16.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PPS Matrix:\n",
            "                    x                 y   ppscore            case  \\\n",
            "0                 age               age  1.000000  predict_itself   \n",
            "1                 age         workclass  0.011232  classification   \n",
            "2                 age            fnlwgt  0.000000      regression   \n",
            "3                 age         education  0.052315  classification   \n",
            "4                 age     education_num  0.000000      regression   \n",
            "..                ...               ...       ...             ...   \n",
            "319  capital_gain_log    native_country  0.000000  classification   \n",
            "320  capital_gain_log            income  0.297578  classification   \n",
            "321  capital_gain_log    capital_change  0.845392      regression   \n",
            "322  capital_gain_log   education_years  0.013555      regression   \n",
            "323  capital_gain_log  capital_gain_log  1.000000  predict_itself   \n",
            "\n",
            "     is_valid_score               metric  baseline_score   model_score  \\\n",
            "0              True                 None        0.000000      1.000000   \n",
            "1              True          weighted F1        0.579088      0.583816   \n",
            "2              True  mean absolute error    75872.186200  77535.141544   \n",
            "3              True          weighted F1        0.201200      0.242989   \n",
            "4              True  mean absolute error        1.853000      1.898306   \n",
            "..              ...                  ...             ...           ...   \n",
            "319            True          weighted F1        0.841082      0.840063   \n",
            "320            True          weighted F1        0.653115      0.756341   \n",
            "321            True  mean absolute error     1188.826600    183.802096   \n",
            "322            True  mean absolute error       11.520800     11.364631   \n",
            "323            True                 None        0.000000      1.000000   \n",
            "\n",
            "                        model  \n",
            "0                        None  \n",
            "1    DecisionTreeClassifier()  \n",
            "2     DecisionTreeRegressor()  \n",
            "3    DecisionTreeClassifier()  \n",
            "4     DecisionTreeRegressor()  \n",
            "..                        ...  \n",
            "319  DecisionTreeClassifier()  \n",
            "320  DecisionTreeClassifier()  \n",
            "321   DecisionTreeRegressor()  \n",
            "322   DecisionTreeRegressor()  \n",
            "323                      None  \n",
            "\n",
            "[324 rows x 9 columns]\n",
            "\n",
            "Correlation Matrix:\n",
            "                       age    fnlwgt  education_num  capital_gain  \\\n",
            "age               1.000000 -0.076646       0.036527      0.077674   \n",
            "fnlwgt           -0.076646  1.000000      -0.043195      0.000432   \n",
            "education_num     0.036527 -0.043195       1.000000      0.122630   \n",
            "capital_gain      0.077674  0.000432       0.122630      1.000000   \n",
            "capital_loss      0.057775 -0.010252       0.079923     -0.031615   \n",
            "hours_per_week    0.068756 -0.018768       0.148123      0.078409   \n",
            "capital_change    0.074284  0.000988       0.117891      0.998521   \n",
            "education_years   0.982927 -0.082775       0.219779      0.098405   \n",
            "capital_gain_log  0.124183 -0.004414       0.129135      0.564520   \n",
            "\n",
            "                  capital_loss  hours_per_week  capital_change  \\\n",
            "age                   0.057775        0.068756        0.074284   \n",
            "fnlwgt               -0.010252       -0.018768        0.000988   \n",
            "education_num         0.079923        0.148123        0.117891   \n",
            "capital_gain         -0.031615        0.078409        0.998521   \n",
            "capital_loss          1.000000        0.054256       -0.085902   \n",
            "hours_per_week        0.054256        1.000000        0.075207   \n",
            "capital_change       -0.085902        0.075207        1.000000   \n",
            "education_years       0.071115        0.094392        0.094222   \n",
            "capital_gain_log     -0.064840        0.083821        0.566241   \n",
            "\n",
            "                  education_years  capital_gain_log  \n",
            "age                      0.982927          0.124183  \n",
            "fnlwgt                  -0.082775         -0.004414  \n",
            "education_num            0.219779          0.129135  \n",
            "capital_gain             0.098405          0.564520  \n",
            "capital_loss             0.071115         -0.064840  \n",
            "hours_per_week           0.094392          0.083821  \n",
            "capital_change           0.094222          0.566241  \n",
            "education_years          1.000000          0.145004  \n",
            "capital_gain_log         0.145004          1.000000  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
            "  warnings.warn(\n",
            "<ipython-input-7-569d764ba7c4>:12: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
            "  correlation_matrix = data.corr()\n"
          ]
        }
      ],
      "source": [
        "#To apply the Predictive Power Score (PPS) to find and discuss the relationships between features, we'll use the ppscore library\n",
        "!pip install ppscore\n",
        "import ppscore as pps\n",
        "# Calculate the PPS matrix\n",
        "pps_matrix = pps.matrix(data)\n",
        "\n",
        "# Display the PPS matrix\n",
        "print(\"PPS Matrix:\")\n",
        "print(pps_matrix)\n",
        "\n",
        "# Compare with the correlation matrix\n",
        "correlation_matrix = data.corr()\n",
        "\n",
        "# Display the correlation matrix\n",
        "print(\"\\nCorrelation Matrix:\")\n",
        "print(correlation_matrix)"
      ]
    },
    {
      "cell_type": "raw",
      "id": "ff2fac39-d53f-4dbe-880a-2a896683b529",
      "metadata": {
        "id": "ff2fac39-d53f-4dbe-880a-2a896683b529"
      },
      "source": [
        "PPS Matrix:\n",
        "Measures the predictive power of one feature with respect to another feature, considering both classification and regression tasks.\n",
        "Provides a holistic view of feature relationships, capturing both linear and non-linear associations.\n",
        "Scores range from 0 to 1, where 0 indicates no predictive power and 1 indicates perfect predictive power.\n",
        "Helpful for identifying important predictors and potential feature interactions.\n",
        "Correlation Matrix:\n",
        "Measures the linear relationship between pairs of features.\n",
        "Provides insights into the strength and direction of linear associations between features.\n",
        "Scores range from -1 to 1, where 1 indicates a perfect positive linear relationship, -1 indicates a perfect negative linear relationship, and 0 indicates no linear relationship.\n",
        "Useful for identifying linear dependencies between features.\n",
        "Now, let's compare the findings from the PPS matrix with the correlation matrix:\n",
        "\n",
        "Comparison of Strength of Relationships:\n",
        "PPS Matrix: Provides insights into both linear and non-linear relationships between features. It can capture relationships that may not be apparent from the correlation matrix.\n",
        "Correlation Matrix: Focuses on linear relationships only. It may not capture non-linear associations between features.\n",
        "Comparison of Feature Importance:\n",
        "PPS Matrix: Identifies features that are most informative for predicting other features, considering both linear and non-linear aspects.\n",
        "Correlation Matrix: Identifies features that have strong linear associations with other features. It may overlook non-linear associations that are captured by the PPS matrix.\n",
        "Comparison of Interpretability:\n",
        "PPS Matrix: Provides intuitive insights into feature relationships based on predictive power, which can be easier to interpret in some cases.\n",
        "Correlation Matrix: Provides insights into linear relationships but may be less intuitive for non-linear associations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ddb338c3-9fba-4235-8c71-da5a3f2e3a4c",
      "metadata": {
        "id": "ddb338c3-9fba-4235-8c71-da5a3f2e3a4c"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}